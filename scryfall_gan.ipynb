{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scryfall.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJeP2jvHa6TW7oQtUGj/kG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXod4f8EqFvv",
        "colab_type": "text"
      },
      "source": [
        "A bit of setup code, for importing TensorFlow and implementing a keras GAN\n",
        "Also connecting to drive so we can use the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra9YuRWvoRHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "92bb318f-5b42-4c62-a738-043bbfcd3c5d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import glob\n",
        "import imageio\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNlXbohqqUhp",
        "colab_type": "text"
      },
      "source": [
        "Now I'll load the data from google drive and setup some constants. The drive location of the dataset will be DATA_PATH. I won't share the dataset itself, but the code needed to automatically download it can be found here: https://github.com/RaesakAce/scryfall-analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxKz6CL0uJ_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "65d7dc00-486a-4b67-d3ab-97401f448fd8"
      },
      "source": [
        " \n",
        "# Training data is also scaled to this.\n",
        "# Note GENERATE_RES 4 or higher  \n",
        "# will blow Google CoLab's memory and have not\n",
        "# been tested extensivly.\n",
        "GENERATE_RES = 1 # Generation resolution factor \n",
        "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
        "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "# Preview image \n",
        "PREVIEW_ROWS = 4\n",
        "PREVIEW_COLS = 7\n",
        "PREVIEW_MARGIN = 16\n",
        "\n",
        "# Size vector to generate images from\n",
        "SEED_SIZE = 100\n",
        "\n",
        "# Configuration\n",
        "DATA_PATH = '/content/drive/My Drive/scryfall-analysis/data_images'\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 60000\n",
        "\n",
        "print(f\"Will generate {GENERATE_SQUARE}px square images.\")\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will generate 32px square images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L269AKGD1zbT",
        "colab_type": "text"
      },
      "source": [
        "Here we transform the images in a numpy binary. The file is pretty big even with the resizing, and loading about 20000 images takes time, so if we don't cache the binary, it will be a long process loading everything every time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3d2_SfPwwRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "23d61c04-6704-407b-e445-f26e917b8d1c"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "training_binary_path = os.path.join(DATA_PATH,\n",
        "        f'training_data_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npy')\n",
        "\n",
        "print(f\"Looking for file: {training_binary_path}\")\n",
        "\n",
        "if not os.path.isfile(training_binary_path):                      \n",
        "  start = time.time()\n",
        "  print(\"Loading training images...\")\n",
        "\n",
        "  training_data = []\n",
        "  images_path = os.path.join(DATA_PATH,'jpegs')\n",
        "  for filename in tqdm(os.listdir(images_path)):\n",
        "      path = os.path.join(images_path,filename)\n",
        "      image = Image.open(path)\n",
        "      width, height = image.size\n",
        "      image = image.crop((height/1.363,0,height/1.363,0))\n",
        "      image = image.resize((GENERATE_SQUARE,GENERATE_SQUARE),Image.ANTIALIAS)                                                     \n",
        "      training_data.append(np.asarray(image))\n",
        "  training_data = np.reshape(training_data,(-1,GENERATE_SQUARE,\n",
        "            GENERATE_SQUARE,IMAGE_CHANNELS))\n",
        "  training_data = training_data.astype(np.float32)\n",
        "  training_data = training_data / 127.5 - 1.\n",
        "\n",
        "\n",
        "  print(\"Saving training image binary...\")\n",
        "  np.save(training_binary_path,training_data)\n",
        "  elapsed = time.time()-start\n",
        "  print (f'Image preprocess time: {hms_string(elapsed)}')\n",
        "else:\n",
        "  print(\"Loading previous training data...\")\n",
        "  training_data = np.load(training_binary_path)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking for file: /content/drive/My Drive/scryfall-analysis/data_images/training_data_32_32.npy\n",
            "Loading previous training data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XRT3EFD21ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahMfiH_34okT",
        "colab_type": "text"
      },
      "source": [
        "Now implementing the actual GAN, defining the functions for creating the discriminator and the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiKvd5zV470G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(seed_size, channels):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
        "    model.add(Reshape((4,4,256)))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "   \n",
        "    # Output resolution, additional upsampling\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    if GENERATE_RES>1:\n",
        "      model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
        "      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Final CNN layer\n",
        "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_discriminator(image_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
        "                     padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CQfGC045E8n",
        "colab_type": "text"
      },
      "source": [
        "This will be an function useful to track the progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvG_nRSQ5LmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(cnt,noise):\n",
        "  image_array = np.full(( \n",
        "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
        "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
        "      255, dtype=np.uint8)\n",
        "  \n",
        "  generated_images = generator.predict(noise)\n",
        "\n",
        "  generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "  image_count = 0\n",
        "  for row in range(PREVIEW_ROWS):\n",
        "      for col in range(PREVIEW_COLS):\n",
        "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE]= generated_images[image_count] * 255\n",
        "        image_count += 1\n",
        "\n",
        "          \n",
        "  output_path = os.path.join(DATA_PATH,'output')\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "  \n",
        "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
        "  im = Image.fromarray(image_array)\n",
        "  im.save(filename)\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03XnKEgE5M6e",
        "colab_type": "text"
      },
      "source": [
        "Let's create the generator and the discriminator and see what they do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qfuDdA_5Xxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "559756d4-4b52-4b96-a0e5-1be4b7f005d6"
      },
      "source": [
        "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
        "\n",
        "noise = tf.random.normal([1, SEED_SIZE])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa5f6afdeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkeD8sWh5aFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e81d91b-acb3-4571-b0ee-8f6616c7c29d"
      },
      "source": [
        "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
        "\n",
        "discriminator = build_discriminator(image_shape)\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.49969888]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ8XKuSUA0a5",
        "colab_type": "text"
      },
      "source": [
        "Now we have to define the loss function. We can't just use backpropagation because we cannot adjust the weight of the discriminator based on the combined results of the generator and discriminator, since this will make the discriminator become really bad in order to mainimize the generator loss function. First lets define a useful function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEsYQKy6MEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkFqdjHZBUfa",
        "colab_type": "text"
      },
      "source": [
        "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOefbxRMBqyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXzaygpVBsu9",
        "colab_type": "text"
      },
      "source": [
        "Next comes the generator loss method. This method will compare the discriminators decisions on the generated images to an array of 1s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLqMeVFCCpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBNpPat0CZ3C",
        "colab_type": "text"
      },
      "source": [
        "Since they will be trained separately, generator and discriminator will use separate optimizers. We'll use Adam and we'll need to give it same learning rate and momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKld1WCECZVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFeL-PhiEJ6x",
        "colab_type": "text"
      },
      "source": [
        "This task may require a long time and be interrupted. It's useful to use checkpoints for this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWYRoxsyEh2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = os.path.join(DATA_PATH,'./training_checkpoints')\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lufhBZaSFEbi",
        "colab_type": "text"
      },
      "source": [
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi6jqcNHFkCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(seed, training=True)\n",
        "\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    \n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "  return gen_loss,disc_loss"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HGCmsj_FukZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\n",
        "  start = time.time()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    gen_loss_list = []\n",
        "    disc_loss_list = []\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      t = train_step(image_batch)\n",
        "      gen_loss_list.append(t[0])\n",
        "      disc_loss_list.append(t[1])\n",
        "\n",
        "    #let's save a checkpoint every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
        "    d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
        "\n",
        "    epoch_elapsed = time.time()-epoch_start\n",
        "    print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},{hms_string(epoch_elapsed)}')\n",
        "    save_images(epoch,fixed_seed)\n",
        "\n",
        "  elapsed = time.time()-start\n",
        "  print (f'Training time: {hms_string(elapsed)}')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZntWuVN2GhHz",
        "colab_type": "text"
      },
      "source": [
        "Time to train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYp9FI87GjUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "outputId": "3b6b1879-47fc-44f9-91ee-84fac846370a"
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, gen loss=0.6886562705039978,disc loss=1.3817002773284912,0:01:01.16\n",
            "Epoch 2, gen loss=0.6930481791496277,disc loss=1.3863028287887573,0:00:56.16\n",
            "Epoch 3, gen loss=0.6931366324424744,disc loss=1.3862993717193604,0:00:56.13\n",
            "Epoch 4, gen loss=0.6931430101394653,disc loss=1.3862981796264648,0:00:56.19\n",
            "Epoch 5, gen loss=0.6931460499763489,disc loss=1.3862981796264648,0:00:56.17\n",
            "Epoch 6, gen loss=0.6931484341621399,disc loss=1.386298418045044,0:00:56.18\n",
            "Epoch 7, gen loss=0.6931488513946533,disc loss=1.3862981796264648,0:00:56.14\n",
            "Epoch 8, gen loss=0.6931486129760742,disc loss=1.3862981796264648,0:00:56.14\n",
            "Epoch 9, gen loss=0.6931485533714294,disc loss=1.3862979412078857,0:00:56.26\n",
            "Epoch 10, gen loss=0.6931489109992981,disc loss=1.3862981796264648,0:00:56.26\n",
            "Epoch 11, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.24\n",
            "Epoch 12, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.23\n",
            "Epoch 13, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.22\n",
            "Epoch 14, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.18\n",
            "Epoch 15, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.45\n",
            "Epoch 16, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.21\n",
            "Epoch 17, gen loss=0.6931490898132324,disc loss=1.3862982988357544,0:00:56.24\n",
            "Epoch 18, gen loss=0.6929633021354675,disc loss=1.3863476514816284,0:00:56.20\n",
            "Epoch 19, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.31\n",
            "Epoch 20, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.22\n",
            "Epoch 21, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.28\n",
            "Epoch 22, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.22\n",
            "Epoch 23, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.22\n",
            "Epoch 24, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:55.80\n",
            "Epoch 25, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:55.92\n",
            "Epoch 26, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.16\n",
            "Epoch 27, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.20\n",
            "Epoch 28, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.18\n",
            "Epoch 29, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.15\n",
            "Epoch 30, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.47\n",
            "Epoch 31, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.12\n",
            "Epoch 32, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.18\n",
            "Epoch 33, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.11\n",
            "Epoch 34, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.11\n",
            "Epoch 35, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.10\n",
            "Epoch 36, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:55.91\n",
            "Epoch 37, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.08\n",
            "Epoch 38, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.15\n",
            "Epoch 39, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.15\n",
            "Epoch 40, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.13\n",
            "Epoch 41, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.18\n",
            "Epoch 42, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.19\n",
            "Epoch 43, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.19\n",
            "Epoch 44, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.19\n",
            "Epoch 45, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.41\n",
            "Epoch 46, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.14\n",
            "Epoch 47, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.12\n",
            "Epoch 48, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.18\n",
            "Epoch 49, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.19\n",
            "Epoch 50, gen loss=0.6931491494178772,disc loss=1.3862982988357544,0:00:56.19\n",
            "Training time: 0:46:57.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfFMz-JcGvuL",
        "colab_type": "text"
      },
      "source": [
        "In case the checkpoint is needed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnDehR5YGtyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxHo7OSwG607",
        "colab_type": "text"
      },
      "source": [
        "Now let's use imageio to create a gif with the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWvEb_hDHGb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d6722293-b3ef-4357-8745-97b4a8f1914b"
      },
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob(os.path.join(DATA_PATH,'output','train*.png'))\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(anim_file)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ac7446ea-e0cb-49e1-9729-436fa120b233\", \"dcgan.gif\", 591475)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}